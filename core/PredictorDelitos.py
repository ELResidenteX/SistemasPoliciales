# ==========================================================
#  PREDICCI√ìN DE ZONAS CR√çTICAS DE INCIDENTES POLICIALES
#  Versi√≥n profesional con predictor de hora cr√≠tica
# ==========================================================

# Paso 1: Instalar librer√≠as (solo si no las tienes)
# --------------------------------------
# pip install pandas scikit-learn requests matplotlib seaborn xgboost joblib

# Paso 2: Importar librer√≠as
# --------------------------------------
import pandas as pd
import numpy as np
import requests
import random
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, roc_curve, confusion_matrix
from sklearn.utils import resample
import joblib

# ==========================================================
# Paso 3: Conectar con tu backend Django (Railway)
# ==========================================================
BASE_URL = "https://web-production-6ee8.up.railway.app"
endpoint = f"{BASE_URL}/api/eventos-por-comuna/?comuna=Santiago&fecha_inicio=2025-09-01&fecha_fin=2025-10-23"

print("üì° Conectando con el backend...")
response = requests.get(endpoint)

if response.status_code != 200:
    raise Exception(f"‚ùå Error al conectar con el backend: {response.status_code}")

data = response.json()
print(f"‚úÖ Conexi√≥n exitosa. Se recibieron {len(data)} eventos.")

df = pd.DataFrame(data)
print("\nüìã Vista previa de los datos recibidos:")
print(df.head())

# ==========================================================
# Paso 4: Preprocesamiento de datos
# ==========================================================
print("\nüîß Procesando datos...")

print("Columnas detectadas:", df.columns.tolist())

# Simulaci√≥n de variables temporales (reemplazar con reales si est√°n disponibles)
df["hora"] = np.random.randint(0, 24, len(df))
df["dia_semana"] = np.random.randint(0, 7, len(df))
df["mes"] = random.randint(1, 10)
df["cantidad_incidentes"] = 1

dataset = (
    df.groupby(["hora", "dia_semana", "mes"])
      .size()
      .reset_index(name="cantidad_incidentes")
)
dataset["riesgo"] = (dataset["cantidad_incidentes"] >= 3).astype(int)

print("\n‚úÖ Dataset final listo para entrenamiento:")
print(dataset.head())

# ==========================================================
# Paso 5: Balanceo y Entrenamiento del modelo
# ==========================================================
print("\nü§ñ Entrenando modelo RandomForestClassifier...")

# Balanceo de clases
mayor = dataset[dataset.riesgo==0]
menor = dataset[dataset.riesgo==1]
if len(menor) > 0:
    menor_upsampled = resample(menor, replace=True, n_samples=len(mayor), random_state=42)
    dataset_balanceado = pd.concat([mayor, menor_upsampled])
else:
    dataset_balanceado = dataset.copy()

X = dataset_balanceado[["hora", "dia_semana", "mes", "cantidad_incidentes"]]
y = dataset_balanceado["riesgo"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

modelo = RandomForestClassifier(n_estimators=150, random_state=42)
modelo.fit(X_train, y_train)
joblib.dump(modelo, "modelo_zonas_criticas.pkl")

# ==========================================================
# Paso 6: Evaluaci√≥n del modelo
# ==========================================================
print("\nüìà Evaluando modelo...")
y_pred = modelo.predict(X_test)

acc = accuracy_score(y_test, y_pred)
print(f"üîπ Precisi√≥n del modelo: {acc*100:.2f}%\n")
print("üîπ Reporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))

# Solo graficar si hay m√°s de una clase
if len(modelo.classes_) > 1:
    # Curva ROC
    fpr, tpr, _ = roc_curve(y_test, modelo.predict_proba(X_test)[:,1])
    plt.figure(figsize=(6,5))
    plt.plot(fpr, tpr, label=f"AUC = {np.trapz(tpr, fpr):.2f}")
    plt.title("Curva ROC - Modelo de Riesgo Delictual")
    plt.xlabel("Falsos Positivos")
    plt.ylabel("Verdaderos Positivos")
    plt.legend()
    plt.grid(True, linestyle="--", alpha=0.6)
    plt.show()
else:
    print("‚ö†Ô∏è No se puede generar la curva ROC: solo hay una clase en los datos de prueba.")

# Matriz de Confusi√≥n
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Greens")
plt.title("Matriz de Confusi√≥n")
plt.show()


# ==========================================================
# Paso EXTRA 1: Calles o direcciones con m√°s incidentes
# ==========================================================
print("\nüìç Probabilidad de ocurrencia de delitos por calle:")

if "direccion" in df.columns:
    total_incidentes = len(df)
    top_direcciones = (
        df["direccion"]
        .value_counts()
        .reset_index()
    )
    top_direcciones.columns = ["direccion", "total"]
    top_direcciones["probabilidad"] = (top_direcciones["total"] / total_incidentes * 100).round(2)
    top_direcciones = top_direcciones.head(5)

    for i, row in top_direcciones.iterrows():
        print(f"{i+1}. {row['direccion']} ‚Äî {row['total']} incidentes ‚Äî {row['probabilidad']}% de probabilidad")

    calle_mas_riesgo = top_direcciones.loc[top_direcciones["probabilidad"].idxmax()]
    print(f"\nüö® Calle con mayor probabilidad de delito:")
    print(f"   üìç {calle_mas_riesgo['direccion']} ‚Äî {calle_mas_riesgo['probabilidad']}% de probabilidad hist√≥rica.")
else:
    print("‚ö†Ô∏è No hay campo 'direccion' disponible en los datos.")

# ==========================================================
# Paso EXTRA 2: Probabilidad global de riesgo
# ==========================================================
total = len(dataset)
riesgo_alto = dataset["riesgo"].sum()
prob_global = (riesgo_alto / total * 100) if total > 0 else 0

print(f"\nüìä Probabilidad global de delitos en la comuna: {prob_global:.2f}%")

# ==========================================================
# Paso EXTRA 3: Predicci√≥n de hora m√°s probable (hist√≥rico + modelo)
# ==========================================================
print("\n‚è∞ Analizando horas de mayor probabilidad delictiva...")

if "hora" in dataset.columns:
    horas = dataset.groupby("hora")["cantidad_incidentes"].sum().reset_index()
    total_incidentes_horas = horas["cantidad_incidentes"].sum()
    horas["probabilidad_%"] = (horas["cantidad_incidentes"] / total_incidentes_horas * 100).round(2)
    horas = horas.sort_values(by="probabilidad_%", ascending=False).reset_index(drop=True)

    print("\nüïí Horas m√°s cr√≠ticas (mayor probabilidad hist√≥rica):")
    for i, row in horas.head(3).iterrows():
        print(f"{i+1}. {int(row['hora']):02d}:00 ‚Äî {row['probabilidad_%']}%")

    hora_max = int(horas.iloc[0]['hora'])
    prob_max = horas.iloc[0]['probabilidad_%']

    print(f"\nüö® Hora con mayor probabilidad de delitos (hist√≥rico):")
    print(f"   üïê {hora_max:02d}:00 ‚Äî {prob_max}% de probabilidad hist√≥rica")

    # Simulaci√≥n predictiva del modelo
    horas_pred = pd.DataFrame({
        "hora": list(range(24)),
        "dia_semana": [3]*24,
        "mes": [10]*24,
        "cantidad_incidentes": [2]*24
    })
    horas_pred["prob_riesgo"] = modelo.predict_proba(horas_pred)[:,1]
    hora_pred_max = horas_pred.loc[horas_pred["prob_riesgo"].idxmax()]

    print(f"\nüîÆ Seg√∫n el modelo, la hora con MAYOR riesgo proyectado es:")
    print(f"   üïì {int(hora_pred_max['hora']):02d}:00 ‚Äî {hora_pred_max['prob_riesgo']*100:.2f}% de probabilidad de riesgo")

    # Gr√°fico visual
    plt.figure(figsize=(10,5))
    plt.bar(horas["hora"], horas["probabilidad_%"], color="darkred", alpha=0.8)
    plt.title("Probabilidad de Ocurrencia de Delitos por Hora del D√≠a")
    plt.xlabel("Hora del D√≠a")
    plt.ylabel("Probabilidad (%)")
    plt.xticks(range(0,24))
    plt.grid(axis="y", linestyle="--", alpha=0.6)
    plt.show()
else:
    print("‚ö†Ô∏è No se encontr√≥ la columna 'hora' en el dataset.")

# ==========================================================
# Paso 9: Conclusi√≥n Final
# ==========================================================
print("""
üìò CONCLUSI√ìN
El modelo RandomForest fue entrenado con datos hist√≥ricos del sistema policial.
Ahora, adem√°s de estimar zonas cr√≠ticas y calles de riesgo,
se incorpora un predictor de la hora m√°s probable de ocurrencia delictiva,
basado en an√°lisis hist√≥rico y proyecci√≥n del modelo.
Esto permite reforzar patrullajes preventivos y focalizar recursos operativos
en las franjas horarias con mayor vulnerabilidad.
""")

